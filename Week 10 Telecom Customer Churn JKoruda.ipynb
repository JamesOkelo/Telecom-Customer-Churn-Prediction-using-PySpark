{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN829yHaQggG"
      },
      "source": [
        "# Week 10 Telecom Customer Churn Prediction using PySpark-JKoruda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Femiv79eRl2l"
      },
      "source": [
        "## Problem Definition\n",
        "The goal of this project is to develop a machine learning model using PySpark that accurately\n",
        "predicts customer churn in a telecom company. The model should achieve a minimum accuracy of\n",
        "0.8, enabling the company to proactively identify and retain customers at risk of leaving. By\n",
        "effectively predicting churn, the company can implement targeted retention strategies, reduce\n",
        "customer attrition, and improve overall business performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Guidelines\n",
        "● Dataset: Obtain a telecom customer dataset that includes relevant features such as\n",
        "customer demographics, usage patterns, service plans, call details, customer complaints,\n",
        "and churn status. You can use this dataset.\n",
        "● Data Preprocessing: Perform necessary preprocessing steps on the dataset, including\n",
        "handling missing values, feature scaling, encoding categorical variables, and splitting the\n",
        "data into training and testing sets. Consider using PySpark's DataFrame API for efficient data\n",
        "manipulation.\n",
        "● Feature Engineering: Create new features from the existing dataset that might be helpful for\n",
        "predicting churn. For example, you could calculate metrics such as call duration, average\n",
        "monthly spend, customer tenure, or customer satisfaction scores.\n",
        "● Model Selection and Training: Choose an appropriate machine learning algorithm for churn\n",
        "prediction, considering the nature of the problem and the dataset characteristics. PySpark\n",
        "provides various algorithms such as logistic regression, random forests, gradient boosting,\n",
        "and support vector machines. Experiment with different models and hyperparameter\n",
        "configurations to achieve the desired accuracy of 0.8.\n",
        "● Model Evaluation: Assess the performance of the trained models using appropriate\n",
        "evaluation metrics such as accuracy, precision, recall, and F1-score.\n",
        "● Documentation and Reporting: Maintain clear documentation throughout the project,\n",
        "including details about the dataset, preprocessing steps, feature engineering, model\n",
        "selection, and evaluation results. Summarize the project findings, challenges faced, and\n",
        "lessons learned in a final report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRV5SYyobmhp",
        "outputId": "c7729e12-49b7-40ac-d580-d5e5f24e6afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=8a149a1cf48e56400656635f3fe07a9e2fda7a04c7b33e5d5e50fb9a8d927c28\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "#install pyspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AYuP1rXdaazs"
      },
      "outputs": [],
      "source": [
        "## Import the libraries\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark import SparkContext\n",
        "import os\n",
        "import urllib.request\n",
        "from pyspark.sql.functions import col\n",
        "import matplotlib.pyplot as plt\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler, MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SXPb1bpYamnr"
      },
      "outputs": [],
      "source": [
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"Churn101\").getOrCreate()\n",
        "\n",
        "# Local file path to save the downloaded CSV file\n",
        "local_file_path = os.getcwd() + \"/telecom_dataset.csv\"\n",
        "\n",
        "#Dataset URL\n",
        "data_url = \"https://archive.org/download/telecom_dataset/telecom_dataset.csv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jIgtJpTjfwB1"
      },
      "outputs": [],
      "source": [
        "# Download the CSV file\n",
        "urllib.request.urlretrieve(data_url, local_file_path)\n",
        "\n",
        "# Fetch and load dataset: https://archive.org/download/telecom_dataset/telecom_dataset.csv\n",
        "df = spark.read.csv(local_file_path, header=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlkrDmQgemv1"
      },
      "source": [
        "### Initial Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y49eKXgah8d_",
        "outputId": "2d2c03ad-b2c6-4ef5-cdd3-5384ef3b5ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+---+--------------+--------------+------------+-----+\n",
            "|CustomerID|Gender|Age|      Contract|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+---+--------------+--------------+------------+-----+\n",
            "|         1|Female| 25|Month-to-Month|          65.7|       156.5|   No|\n",
            "|         2|  Male| 37|      One Year|          89.0|      2356.8|   No|\n",
            "|         3|  Male| 52|      Two Year|         115.5|      5408.6|   No|\n",
            "|         4|Female| 30|Month-to-Month|          75.9|       129.4|  Yes|\n",
            "|         5|  Male| 45|      One Year|          98.2|      3142.0|   No|\n",
            "|         6|Female| 55|      Two Year|          99.9|      6541.5|   No|\n",
            "|         7|  Male| 32|Month-to-Month|          82.1|       267.7|  Yes|\n",
            "|         8|Female| 28|Month-to-Month|          61.5|       346.9|   No|\n",
            "|         9|  Male| 48|      One Year|         101.8|      5149.6|  Yes|\n",
            "|        10|Female| 60|      Two Year|         108.1|      6742.8|  Yes|\n",
            "|        11|  Male| 42|Month-to-Month|          78.9|       547.6|   No|\n",
            "|        12|Female| 35|      One Year|          94.7|      1950.2|   No|\n",
            "|        13|  Male| 41|      Two Year|          96.5|      4188.1|   No|\n",
            "|        14|  Male| 38|Month-to-Month|          79.1|       148.2|  Yes|\n",
            "|        15|Female| 50|      One Year|         105.5|      4759.1|  Yes|\n",
            "|        16|  Male| 47|      Two Year|         112.3|      5432.0|  Yes|\n",
            "|        17|Female| 26|Month-to-Month|          68.2|       289.1|   No|\n",
            "|        18|  Male| 33|Month-to-Month|          75.5|       462.5|  Yes|\n",
            "|        19|Female| 31|      One Year|          85.9|      1673.8|   No|\n",
            "|        20|  Male| 39|      Two Year|          97.1|      3992.4|   No|\n",
            "+----------+------+---+--------------+--------------+------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Preview df data \n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEG9-rV6iVWX",
        "outputId": "5857d344-f0cc-4c10-eb42-df5dd7f98f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns: 7\n",
            "Number of rows: 20\n"
          ]
        }
      ],
      "source": [
        "#Check df shape\n",
        "# Number of columns\n",
        "num_columns = len(df.columns)\n",
        "print(\"Number of columns:\", num_columns)\n",
        "\n",
        "# Number of rows\n",
        "num_rows = df.count()\n",
        "print(\"Number of rows:\", num_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8TQcLJOiAWB",
        "outputId": "63c0d181-ad77-4125-bc2b-00552ddec10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- CustomerID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- MonthlyCharges: string (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#View df schema\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03sMMksDR3po"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeW-XQc4pta3",
        "outputId": "ad773e0e-9e16-4d8f-a618-9de93b0986ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame: 20 rows, 7 columns\n"
          ]
        }
      ],
      "source": [
        "#Drop nulls \n",
        "# Drop null rows\n",
        "df = df.na.drop()\n",
        "\n",
        "# Verify the result\n",
        "print(\"Shape of DataFrame: {} rows, {} columns\".format(df.count(), len(df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hyexhgJqj8k",
        "outputId": "dfe79826-c172-4545-ff74-ae4da87c32fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of DataFrame: 20 rows, 7 columns\n"
          ]
        }
      ],
      "source": [
        "#Drop duplicate row entries\n",
        "df = df.dropDuplicates()\n",
        "\n",
        "# Verify the result\n",
        "print(\"Shape of DataFrame: {} rows, {} columns\".format(df.count(), len(df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEAk6goqryLb",
        "outputId": "9eb76312-7edc-41ad-ea36-3c605e13482b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- CustomerID: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- MonthlyCharges: float (nullable = true)\n",
            " |-- TotalCharges: float (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Cast numeric columns from string type to integer or float\n",
        "# Convert Age column to integer type\n",
        "updated_df = df.withColumn(\"Age\", col(\"Age\").cast(\"integer\"))\n",
        "\n",
        "# Convert MonthlyCharges column to float type\n",
        "updated_df = updated_df.withColumn(\"MonthlyCharges\", col(\"MonthlyCharges\").cast(\"float\"))\n",
        "\n",
        "# Convert TotalCharges column to float type\n",
        "updated_df = updated_df.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"float\"))\n",
        "\n",
        "#View updated schema\n",
        "updated_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMmxOHy3R6q5"
      },
      "source": [
        "### Feature Engineering "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ic74CMUr6xI",
        "outputId": "7c0b4f86-d40d-4f43-dc97-55ee2bcbea76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+---+--------------+--------------+------------+-----+---------+\n",
            "|CustomerID|Gender|Age|      Contract|MonthlyCharges|TotalCharges|Churn|Age_group|\n",
            "+----------+------+---+--------------+--------------+------------+-----+---------+\n",
            "|        16|  Male| 47|      Two Year|         112.3|      5432.0|  Yes|    45-49|\n",
            "|        20|  Male| 39|      Two Year|          97.1|      3992.4|   No|    35-39|\n",
            "|        17|Female| 26|Month-to-Month|          68.2|       289.1|   No|    25-29|\n",
            "|        11|  Male| 42|Month-to-Month|          78.9|       547.6|   No|    40-44|\n",
            "|        18|  Male| 33|Month-to-Month|          75.5|       462.5|  Yes|    30-34|\n",
            "|         7|  Male| 32|Month-to-Month|          82.1|       267.7|  Yes|    30-34|\n",
            "|         4|Female| 30|Month-to-Month|          75.9|       129.4|  Yes|    30-34|\n",
            "|         8|Female| 28|Month-to-Month|          61.5|       346.9|   No|    25-29|\n",
            "|        10|Female| 60|      Two Year|         108.1|      6742.8|  Yes|    60-64|\n",
            "|        13|  Male| 41|      Two Year|          96.5|      4188.1|   No|    40-44|\n",
            "|         5|  Male| 45|      One Year|          98.2|      3142.0|   No|    45-49|\n",
            "|        15|Female| 50|      One Year|         105.5|      4759.1|  Yes|    50-54|\n",
            "|        12|Female| 35|      One Year|          94.7|      1950.2|   No|    35-39|\n",
            "|         3|  Male| 52|      Two Year|         115.5|      5408.6|   No|    50-54|\n",
            "|        14|  Male| 38|Month-to-Month|          79.1|       148.2|  Yes|    35-39|\n",
            "|         6|Female| 55|      Two Year|          99.9|      6541.5|   No|    55-59|\n",
            "|         2|  Male| 37|      One Year|          89.0|      2356.8|   No|    35-39|\n",
            "|         1|Female| 25|Month-to-Month|          65.7|       156.5|   No|    25-29|\n",
            "|         9|  Male| 48|      One Year|         101.8|      5149.6|  Yes|    45-49|\n",
            "|        19|Female| 31|      One Year|          85.9|      1673.8|   No|    30-34|\n",
            "+----------+------+---+--------------+--------------+------------+-----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Add Age_group column\n",
        "\n",
        "# Create a new column 'Age_group' based on 'Age' column\n",
        "df_with_age_group = updated_df.withColumn(\n",
        "    'Age_group',\n",
        "    F.when((F.col('Age') >= 0) & (F.col('Age') < 5), '0-4')\n",
        "    .when((F.col('Age') >= 5) & (F.col('Age') < 10), '5-9')\n",
        "    .when((F.col('Age') >= 10) & (F.col('Age') < 15), '10-14')\n",
        "    .when((F.col('Age') >= 15) & (F.col('Age') < 20), '15-19')\n",
        "    .when((F.col('Age') >= 20) & (F.col('Age') < 25), '20-24')\n",
        "    .when((F.col('Age') >= 25) & (F.col('Age') < 30), '25-29')\n",
        "    .when((F.col('Age') >= 30) & (F.col('Age') < 35), '30-34')\n",
        "    .when((F.col('Age') >= 35) & (F.col('Age') < 40), '35-39')\n",
        "    .when((F.col('Age') >= 40) & (F.col('Age') < 45), '40-44')\n",
        "    .when((F.col('Age') >= 45) & (F.col('Age') < 50), '45-49')\n",
        "    .when((F.col('Age') >= 50) & (F.col('Age') < 55), '50-54')\n",
        "    .when((F.col('Age') >= 55) & (F.col('Age') < 60), '55-59')\n",
        "    .when((F.col('Age') >= 60) & (F.col('Age') < 65), '60-64')\n",
        "    .otherwise('65+')\n",
        ")\n",
        "\n",
        "# Show the updated DataFrame\n",
        "df_with_age_group.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ckYr-zumBw",
        "outputId": "e486b018-743e-4013-f973-141e95b6c64f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+---+--------------+--------------+------------+-----+---------+--------------------+\n",
            "|CustomerID|Gender|Age|      Contract|MonthlyCharges|TotalCharges|Churn|Age_group|   Month_Total_Ratio|\n",
            "+----------+------+---+--------------+--------------+------------+-----+---------+--------------------+\n",
            "|        16|  Male| 47|      Two Year|         112.3|      5432.0|  Yes|    45-49|0.020673785539719772|\n",
            "|        20|  Male| 39|      Two Year|          97.1|      3992.4|   No|    35-39|0.024321210512283167|\n",
            "|        17|Female| 26|Month-to-Month|          68.2|       289.1|   No|    25-29| 0.23590451576753818|\n",
            "|        11|  Male| 42|Month-to-Month|          78.9|       547.6|   No|    40-44|  0.1440832816719086|\n",
            "|        18|  Male| 33|Month-to-Month|          75.5|       462.5|  Yes|    30-34| 0.16324324324324324|\n",
            "|         7|  Male| 32|Month-to-Month|          82.1|       267.7|  Yes|    30-34| 0.30668656978105546|\n",
            "|         4|Female| 30|Month-to-Month|          75.9|       129.4|  Yes|    30-34|  0.5865533624877629|\n",
            "|         8|Female| 28|Month-to-Month|          61.5|       346.9|   No|    25-29| 0.17728452315381624|\n",
            "|        10|Female| 60|      Two Year|         108.1|      6742.8|  Yes|    60-64| 0.01603191576279211|\n",
            "|        13|  Male| 41|      Two Year|          96.5|      4188.1|   No|    40-44|0.023041474117107053|\n",
            "|         5|  Male| 45|      One Year|          98.2|      3142.0|   No|    45-49| 0.03125397738645518|\n",
            "|        15|Female| 50|      One Year|         105.5|      4759.1|  Yes|    50-54|0.022168056530678222|\n",
            "|        12|Female| 35|      One Year|          94.7|      1950.2|   No|    35-39| 0.04855912179227415|\n",
            "|         3|  Male| 52|      Two Year|         115.5|      5408.6|   No|    50-54|0.021354878880775544|\n",
            "|        14|  Male| 38|Month-to-Month|          79.1|       148.2|  Yes|    35-39|  0.5337381923276706|\n",
            "|         6|Female| 55|      Two Year|          99.9|      6541.5|   No|    55-59|0.015271726901456685|\n",
            "|         2|  Male| 37|      One Year|          89.0|      2356.8|   No|    35-39|  0.0377630677851749|\n",
            "|         1|Female| 25|Month-to-Month|          65.7|       156.5|   No|    25-29| 0.41980828720921526|\n",
            "|         9|  Male| 48|      One Year|         101.8|      5149.6|  Yes|    45-49|0.019768525928467784|\n",
            "|        19|Female| 31|      One Year|          85.9|      1673.8|   No|    30-34|0.051320348321186836|\n",
            "+----------+------+---+--------------+--------------+------------+-----+---------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add a new column 'Month_Total_Ratio' by dividing 'MonthlyCharges' / 'TotalCharges'\n",
        "df_with_ratio = df_with_age_group.withColumn(\n",
        "    'Month_Total_Ratio',\n",
        "    F.col('MonthlyCharges') / F.col('TotalCharges')\n",
        ")\n",
        "\n",
        "# Show the updated DataFrame\n",
        "df_with_ratio.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dxZA9dYdu_7A"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling \n",
        "# Define the numerical columns\n",
        "numerical_columns = ['Age', 'MonthlyCharges', 'TotalCharges', 'Month_Total_Ratio']\n",
        "\n",
        "# Assemble the numerical columns into a vector column\n",
        "assembler = VectorAssembler(inputCols=numerical_columns, outputCol=\"vFeatures\")\n",
        "\n",
        "# Create a MinMaxScaler object\n",
        "scaler = MinMaxScaler(inputCol=\"vFeatures\", outputCol=\"scaled_features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EM0AlU7fxkmk"
      },
      "outputs": [],
      "source": [
        "#Categorical encoding\n",
        "\n",
        "catCols = ['Gender', 'Contract', 'Churn', 'Age_group']\n",
        "indexers = []\n",
        "\n",
        "# Iterate over the categorical columns\n",
        "for col in catCols:\n",
        "    # Create a StringIndexer object, and specify the input and output columns\n",
        "    stringindexer = StringIndexer(inputCol=col, outputCol=col+\"_index\")\n",
        "    indexers.append(stringindexer)\n",
        "\n",
        "# Create a Pipeline to chain the StringIndexer stages\n",
        "#-pipeline = Pipeline(stages=indexers)\n",
        "pipeline = Pipeline(stages=[assembler, scaler] + indexers)\n",
        "\n",
        "pipeline_model = pipeline.fit(df_with_ratio)\n",
        "df_encoded = pipeline_model.transform(df_with_ratio)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWrjDYuWR_c1"
      },
      "source": [
        "### Model Selection and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRxFMf8T2qDL",
        "outputId": "8575234c-c68f-46ff-bafc-c9590cbbfc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of Training DataFrame: 15 rows\n",
            "Size of Testing DataFrame: 5 rows\n",
            "root\n",
            " |-- Churn_index: double (nullable = false)\n",
            " |-- mainFeatures: vector (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Feature and Label Target selection\n",
        "\n",
        "feature_columns = [\"scaled_features\", \"Gender_index\", \"Contract_index\", \"Age_group_index\"]\n",
        "label_column = \"Churn_index\"\n",
        "\n",
        "# Vectorize Features\n",
        "vectorAssembler = VectorAssembler(inputCols=feature_columns, outputCol=\"mainFeatures\")\n",
        "v_data = vectorAssembler.transform(df_encoded)\n",
        "\n",
        "#Drop columns which are no longer needed\n",
        "columns_to_drop = [\"CustomerID\", \"Gender\", \"Age\", \"Contract\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\", \"Age_group\", \"Month_Total_Ratio\", \"vFeatures\", \"scaled_features\", \"Gender_index\", \"Contract_index\", \"Age_group_index\"]\n",
        "v_data = v_data.drop(*columns_to_drop)\n",
        "\n",
        "# Split the Data for Training and Testing\n",
        "splits = v_data.randomSplit([0.8, 0.2], seed=42)\n",
        "train_data = splits[0]\n",
        "test_data = splits[1]\n",
        "\n",
        "# Verify the result\n",
        "#train_data.show(truncate=False)\n",
        "print(\"Size of Training DataFrame: {} rows\".format(train_data.count()))\n",
        "print(\"Size of Testing DataFrame: {} rows\".format(test_data.count()))\n",
        "train_data.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OAa2In-n67_C"
      },
      "outputs": [],
      "source": [
        "# Model Selection and Training\n",
        "lr = LogisticRegression(labelCol=\"Churn_index\", featuresCol=\"mainFeatures\")\n",
        "\n",
        "# Create a ParamGrid for grid search\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\t\t   \n",
        "# Define the evaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Churn_index\")\n",
        "\n",
        "# Create CrossValidator with the LogisticRegression model and BinaryClassificationEvaluator\n",
        "cross_validator = CrossValidator(estimator=lr,estimatorParamMaps=param_grid,evaluator=evaluator,numFolds=2)  \n",
        "\n",
        "# Fit the cross-validator to the training data\n",
        "cvModel = cross_validator.fit(train_data)\n",
        "\n",
        "# Evaluate the model using the evaluator\n",
        "accuracy = evaluator.evaluate(cvModel.transform(test_data))\n",
        "\n",
        "# Get the best model\n",
        "best_model = cvModel.bestModel\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzgATJEXSBtt"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hl_KjsmjrDD",
        "outputId": "9356cdf9-8b4b-4324-f9a8-a5ac543ba90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters:\n",
            "aggregationDepth = 2\n",
            "elasticNetParam = 0.0\n",
            "family = auto\n",
            "featuresCol = mainFeatures\n",
            "fitIntercept = True\n",
            "labelCol = Churn_index\n",
            "maxBlockSizeInMB = 0.0\n",
            "maxIter = 100\n",
            "predictionCol = prediction\n",
            "probabilityCol = probability\n",
            "rawPredictionCol = rawPrediction\n",
            "regParam = 0.01\n",
            "standardization = True\n",
            "threshold = 0.5\n",
            "tol = 1e-06\n"
          ]
        }
      ],
      "source": [
        "# Print the best parameters\n",
        "best_params = best_model.extractParamMap()\n",
        "print(\"Best Parameters:\")\n",
        "for param in best_params:\n",
        "    print(param.name, \"=\", best_params[param])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Nn_Xn_ahkKx_"
      },
      "outputs": [],
      "source": [
        "# Create a new instance of LogisticRegression\n",
        "lr_best = LogisticRegression(labelCol=\"Churn_index\", featuresCol=\"mainFeatures\")\n",
        "\n",
        "# Set the best parameters obtained from the CrossValidator above\n",
        "lr_best.setParams(aggregationDepth=2,\n",
        "                  elasticNetParam=0.5,\n",
        "                  family=\"auto\",\n",
        "                  fitIntercept=True,\n",
        "                  maxIter=100,\n",
        "                  regParam=0.01,\n",
        "                  standardization=True,\n",
        "                  threshold=0.5,\n",
        "                  tol=1e-06)\n",
        "\n",
        "# Train the logistic regression model with the best parameters\n",
        "model_best = lr_best.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data using the best model\n",
        "predictions_best = model_best.transform(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFkhLKusmKqG",
        "outputId": "324017a1-deeb-423b-9ebb-78e6a17dfb04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression accuracy: 0.8\n",
            "Logistic Regression Precision: 0.8500000000000001\n",
            "Logistic Regression recall: 0.8\n",
            "Logistic Regression F1-score: 0.7809523809523808\n"
          ]
        }
      ],
      "source": [
        "# Print model evaluation metrics\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Churn_index\")\n",
        "\n",
        "accuracy_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: \"accuracy\"})\n",
        "precision_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: \"weightedPrecision\"})\n",
        "recall_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: \"weightedRecall\"})\n",
        "f1_lr = evaluator.evaluate(predictions_best, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "print(\"Logistic Regression accuracy:\", accuracy_lr)\n",
        "print(\"Logistic Regression Precision:\", precision_lr)\n",
        "print(\"Logistic Regression recall:\", recall_lr)\n",
        "print(\"Logistic Regression F1-score:\", f1_lr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMPHaKp3uwIo/iR48sFzhRT",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
